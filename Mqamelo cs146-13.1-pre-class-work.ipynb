{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance sampling revisited\n",
    "\n",
    "In the previous session, you saw the posterior distribution below for estimating the unknown mean and standard deviation in a Gaussian mixture model. [See the previous pre-class work](https://gist.github.com/cscheffler/b0a31f9a2749804ac1268d9ab20ffa7f) for the model details, if you need to refresh your memory.\n",
    "\n",
    "$$p(\\mu, \\sigma\\,|\\,\\{x\\}) \\propto \\underbrace{\\Bigg.\\text{Normal}(\\mu\\,|\\,0, 5^2)\\,\\text{Gamma}(\\sigma\\,|\\,2, 1)}_{\\text{prior}}\\, \\underbrace{\\prod_{i=1}^{20} \\big[0.7\\text{Normal}(x_i\\,|\\,0,4^2) + 0.3\\text{Normal}(x_i\\,|\\,\\mu,\\sigma^2)\\big]}_{\\text{likelihood}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data set from the model specification\n",
    "data = [\n",
    "  -4.127935, -2.152332, 3.046302, -10.77442, -6.985155, 5.536106, 1.294746,\n",
    "  7.638998, -5.650118, -4.478067, -0.4551435, -3.969413, -0.4225518, -2.462094,\n",
    "  1.886675, 3.095567, 4.310003, 3.305034, 0.8548273, 4.368213]\n",
    "\n",
    "# The unnormalized posterior distribution function, as defined above.\n",
    "def unnormalized_posterior(mu, sigma, data):\n",
    "    if sigma < 0:\n",
    "        # The probably of sigma < 0 is 0. It will become clear why we need this\n",
    "        # a little further down – samples from our proposal distribution might\n",
    "        # have sigma < 0.\n",
    "        return 0\n",
    "    else:\n",
    "        return (\n",
    "            sts.norm.pdf(mu, loc=0, scale=5) *\n",
    "            sts.gamma.pdf(sigma, a=2, scale=1) *\n",
    "            np.prod(\n",
    "                0.7 * sts.norm.pdf(data, loc=0, scale=4) +\n",
    "                0.3 * sts.norm.pdf(data, loc=mu, scale=sigma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1720: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
     ]
    }
   ],
   "source": [
    "# Plot of the unormalized posterior using a 2-d contour plot.\n",
    "plot_mu_range = [-12, 12]\n",
    "plot_sigma_range = [0, 7]\n",
    "\n",
    "mu = np.linspace(plot_mu_range[0], plot_mu_range[1], 300)\n",
    "sigma = np.linspace(plot_sigma_range[0], plot_sigma_range[1], 300)\n",
    "posterior = np.empty((len(sigma), len(mu)))\n",
    "for i in range(len(sigma)):\n",
    "    for j in range(len(mu)):\n",
    "        posterior[i,j] = unnormalized_posterior(mu[j], sigma[i], data)\n",
    "\n",
    "plt.figure(figsize=(11, 10))\n",
    "filled = plt.contourf(mu, sigma, posterior, 11, cmap=plt.cm.YlOrRd_r)\n",
    "lines = plt.contour(mu, sigma, posterior, 11, colors='black')\n",
    "plt.title('Unnormalized posterior over μ and σ.')\n",
    "plt.xlabel('μ')\n",
    "plt.ylabel('σ')\n",
    "color_bar = plt.colorbar(filled)\n",
    "color_bar.add_lines(lines)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we computed some expected values using importance sampling and saw that choosing a good proposal distribution is not necessarily straightforward. How can we monitor convergence of the importance sampling method, and how do we even know if we are converging to the right solution?\n",
    "\n",
    "In this notebook we look at 2 proposal distributions for the task of computing the expected value $E[\\sigma^2]$ under the posterior distribution. The first proposal distribution is provided for you below as a demonstration. Your task (see further down) is to do importance sampling with a second proposal distribution, and to compare the two proposals.\n",
    "\n",
    "## Proposal distribution 1: Bimodal\n",
    "\n",
    "This proposal distribution is designed to put most of its probability mass on the two major peaks seen in the posterior.\n",
    "\n",
    "We generate samples from the distribution and display them on the contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposal distribution: Bimodal. A mixture of two normal distributions over mu\n",
    "# with means at -4 and 4. A single normal distribution over sigma.\n",
    "\n",
    "# Probability density function of the bimodal proposal distribution\n",
    "def bimodal_pdf(mu, sigma):\n",
    "    return (\n",
    "        (\n",
    "            0.5 * sts.norm.pdf(mu, loc=4, scale=1.5) +\n",
    "            0.5 * sts.norm.pdf(mu, loc=-4, scale=1.5)) *\n",
    "        sts.norm.pdf(sigma, loc=1.5, scale=0.75))\n",
    "\n",
    "# Generate samples from the bimodal proposal distribution\n",
    "def bimodal_rvs(size):\n",
    "    # Sample a vector of 0s and 1s, for picking from which normal to sample mu.\n",
    "    selector = sts.bernoulli.rvs(0.5, size=size)    \n",
    "    mu_samples = (\n",
    "        selector * sts.norm.rvs(loc=4, scale=1.5, size=size) +\n",
    "        (1-selector) * sts.norm.rvs(loc=-4, scale=1.5, size=size))\n",
    "\n",
    "    # Repeatedly sample sigmas until they are all greater than 0.\n",
    "    sigma_samples = np.zeros(size)\n",
    "    while True:\n",
    "        not_positive = sigma_samples <= 0\n",
    "        how_many = sum(not_positive)\n",
    "        if how_many == 0:\n",
    "            break\n",
    "        sigma_samples[not_positive] = sts.norm.rvs(loc=1.5, scale=0.75, size=how_many)\n",
    "\n",
    "    return {\n",
    "        'mu': mu_samples,\n",
    "        'sigma': sigma_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "num_samples = 100000\n",
    "proposal_distribution = bimodal_pdf\n",
    "proposal_samples = bimodal_rvs(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the samples on the level plot\n",
    "plt.figure(figsize=(11, 10))\n",
    "filled = plt.contourf(mu, sigma, posterior, 11, cmap=plt.cm.YlOrRd_r)\n",
    "lines = plt.contour(mu, sigma, posterior, 11, colors='black')\n",
    "plt.plot(proposal_samples['mu'], proposal_samples['sigma'], 'k.', alpha=0.1)\n",
    "plt.title('Unnormalized posterior over μ and σ.')\n",
    "plt.xlabel('μ')\n",
    "plt.ylabel('σ')\n",
    "color_bar = plt.colorbar(filled)\n",
    "color_bar.add_lines(lines)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to do importance sampling, we calculate the weights associated with each of these samples as the ratio between the true (unnormalized) pdf and the proposal pdf — $w_i = p(\\mu_i, \\sigma_i) / q(\\mu_i, \\sigma_i).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the importance weights, p(sample) / q(sample)\n",
    "weights = np.empty(num_samples)\n",
    "for i in range(num_samples):\n",
    "    p_value = unnormalized_posterior(proposal_samples['mu'][i], proposal_samples['sigma'][i], data)\n",
    "    q_value = proposal_distribution(proposal_samples['mu'][i], proposal_samples['sigma'][i])\n",
    "    weights[i] = p_value / q_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to approximate $E[\\sigma^2]$ we use the weights and the $\\sigma$ part of our samples from the proposal distribution to calculate the approximation.\n",
    "\n",
    "$$E[\\sigma^2] \\approx \\dfrac{\\sum_i w_i f(\\sigma_i)}{\\sum_i w_i} \\text{ with } f(\\sigma) = \\sigma^2$$\n",
    "\n",
    "We also use the partial sums to plot the convergence of the estimator above as the number of samples, $n$, goes from 1 to 100,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_values = proposal_samples['sigma'] ** 2\n",
    "estimate = np.sum(f_values * weights) / np.sum(weights)\n",
    "print('Estimate for σ² with', num_samples, 'samples:', estimate)\n",
    "\n",
    "convergence = np.cumsum(f_values * weights) / np.cumsum(weights)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.axhline(estimate, color='red')\n",
    "plt.plot(convergence, 'k-')\n",
    "plt.title('Convergence of estimate as a function of the number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal distribution 2: Broad Gaussian distribution\n",
    "\n",
    "Below is the definition of a very different proposal distribution. This one does not try and place most of its probability mass near the peaks of the posterior distribution. Rather, it is a broad Gaussian distribution that tries to cover most of the area (most of the $\\mu$ and $\\sigma$ values) where the posterior seems to have any amount of mass.\n",
    "\n",
    "### Task\n",
    "\n",
    "Repeat the steps that were followed above, for the first proposal distribution.\n",
    "\n",
    " 1. Use this proposal distribution to generate samples.\n",
    " 2. Plot the samples on the contour plot to see which parts of the posterior distribution are targeted by the proposal distribution.\n",
    " 3. Calculate the importance weights and estimate $E[\\sigma^2]$.\n",
    " 4. Comment on the results and compare the results from the two proposal distributions.\n",
    " 5. Which proposal distribution converges more quickly for this estimate?\n",
    " 6. Which proposal distribution do you think is more accurate and why?\n",
    " 7. Comment on how we should go about selecting a good proposal distribution.\n",
    "\n",
    "Paste your plots, results, and answers to each of the questions above in a Google doc, make sure it is shared and be ready to paste a link to your doc into a poll.\n",
    "\n",
    "We build on this activity in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposal distribution: Broad Gaussian. A single normal distribution\n",
    "# over mu and a single normal distribution over sigma.\n",
    "\n",
    "# Probability density function of the broad Gaussian proposal distribution.\n",
    "def broad_pdf(mu, sigma):\n",
    "    # Probability density function of the broad Gaussian proposal distribution.\n",
    "    return (\n",
    "        sts.norm.pdf(mu, loc=0, scale=4) *\n",
    "        sts.norm.pdf(sigma, loc=4, scale=2.5))\n",
    "\n",
    "# Generate samples from the broad Gaussian proposal distribution.\n",
    "def broad_rvs(size):\n",
    "    mu_samples = sts.norm.rvs(loc=0, scale=4, size=size)\n",
    "    sigma_samples = sts.norm.rvs(loc=4, scale=2.5, size=size)\n",
    "    return {\n",
    "        'mu': mu_samples,\n",
    "        'sigma': sigma_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "num_samples = 100000\n",
    "proposal_distribution = broad_pdf\n",
    "proposal_samples = broad_rvs(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 10))\n",
    "filled = plt.contourf(mu, sigma, posterior, 11, cmap=plt.cm.YlOrRd_r)\n",
    "lines = plt.contour(mu, sigma, posterior, 11, colors='black')\n",
    "plt.plot(proposal_samples['mu'], proposal_samples['sigma'], 'k.', alpha=0.1)\n",
    "plt.title(\"Posterior over μ and σ.')\n",
    "plt.xlabel('μ')\n",
    "plt.ylabel('σ')\n",
    "plt.xlim(plot_mu_range[0], plot_mu_range[1])\n",
    "plt.ylim(plot_sigma_range[0], plot_sigma_range[1])\n",
    "color_bar = plt.colorbar(filled)\n",
    "color_bar.add_lines(lines)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.empty(num_samples)\n",
    "for i in range(num_samples):\n",
    "    p_value = unnormalized_posterior(proposal_samples['mu'][i], proposal_samples['sigma'][i], data)\n",
    "    q_value = proposal_distribution(proposal_samples['mu'][i], proposal_samples['sigma'][i])\n",
    "    weights[i] = p_value / q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_values = proposal_samples['sigma'] ** 2\n",
    "estimate = np.sum(f_values * weights) / np.sum(weights)\n",
    "print('σ^2 = {:3f} with {:d} samples'.format(estimate, num_samples))\n",
    "\n",
    "convergence = np.cumsum(f_values * weights) / np.cumsum(weights)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.axhline(estimate, color='red')\n",
    "plt.plot(convergence)\n",
    "plt.title('Convergence')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
